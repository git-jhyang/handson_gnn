{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mendeleev.fetch import fetch_table\n",
    "from torch import nn as pnn\n",
    "from torch.utils import data as pdat\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric import nn as gnn\n",
    "from torch_geometric import data as gdat\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "from monty.serialization import loadfn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import json, torch\n",
    "\n",
    "periodic_table = fetch_table('elements')\n",
    "feats = ['atomic_number', 'atomic_radius', 'atomic_volume', 'group_id', 'period', 'en_pauling']\n",
    "atom_feat_table = periodic_table[feats].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP Data setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property data (band gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'phonopy'\n",
      "No module named 'phonopy'\n"
     ]
    }
   ],
   "source": [
    "mp_prop_data = loadfn('../data/mp_Li_O_3ele_clean.monty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1474, 369)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.arange(len(mp_prop_data))\n",
    "train_index, test_index = train_test_split(index, test_size = 0.2, random_state=123)\n",
    "\n",
    "train_data = np.array(mp_prop_data)[sorted(train_index)]\n",
    "test_data = np.array(mp_prop_data)[sorted(test_index)]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strucutre_to_graph(structure, r=3):\n",
    "    neighbors = structure.get_all_neighbors(r=r)\n",
    "    pairs = []\n",
    "    atoms = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for i, nns in enumerate(neighbors):\n",
    "        atoms.append(structure[i].specie.number - 1)\n",
    "        for n in nns:\n",
    "            pair = (i, n.index, f'{n.nn_distance:.8f}')\n",
    "            if pair not in pairs:\n",
    "                pairs.append(pair)\n",
    "                edge_index.append(pair[:2])\n",
    "                edge_attr.append(float(pair[2]))\n",
    "    x = atom_feat_table[atoms]\n",
    "    return {'x':x, 'edge_index':np.array(edge_index), 'edge_attr':np.array(edge_attr)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pytorch geometric (PyG)](https://pytorch-geometric.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "Graph 데이터를 효율적으로 다룰 수 있도록 돕는 pytorch library로, GNN에 특화된 pytorch 기능들을 제공함\n",
    "\n",
    "특히 Graph data를 다루는데 있어, torch_geometric의 dataset, dataloader 등을 활용하면 복잡한 과정들을 생략할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyG를 활용한 dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoDataset(gdat.Dataset):\n",
    "    def __init__(self, mp_dataset, target='band_gap', r=3):\n",
    "        super(GeoDataset, self).__init__()\n",
    "        self._data = []\n",
    "        for mp_data in mp_dataset:\n",
    "            data = strucutre_to_graph(mp_data['structure'], r=r)\n",
    "            # torch_geometric.data 의 Data object를 이용해 하나의 데이터를 구성\n",
    "            self._data.append(gdat.Data(\n",
    "                x = torch.from_numpy(data['x']).float(), \n",
    "                edge_index = torch.from_numpy(data['edge_index'].T).long(), \n",
    "                edge_attr = torch.from_numpy(data['edge_attr']).float().view(-1,1),\n",
    "                y = torch.tensor(mp_data[target]).float().view(-1,1)\n",
    "            ))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # 개별 데이터는 torch_geometric.data 의 Data object를 그대로 반환\n",
    "        if isinstance(i, (list, tuple)):\n",
    "            return [self._data[_i] for _i in i]\n",
    "        return self._data[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[92, 6], edge_index=[2, 834], edge_attr=[834, 1], y=[4, 1], batch=[92], ptr=[5])\n",
      "--------------------------------------------------------------------------------\n",
      "Data(x=[6, 6], edge_index=[2, 34], edge_attr=[34, 1], y=[1, 1])\n",
      "Data(x=[7, 6], edge_index=[2, 62], edge_attr=[62, 1], y=[1, 1])\n",
      "Data(x=[60, 6], edge_index=[2, 602], edge_attr=[602, 1], y=[1, 1])\n",
      "Data(x=[19, 6], edge_index=[2, 136], edge_attr=[136, 1], y=[1, 1])\n"
     ]
    }
   ],
   "source": [
    "test_dataset_geo = GeoDataset(test_data)\n",
    "test_dl_geo = GeoDataLoader(test_dataset_geo, batch_size=4)\n",
    "batch_geo = next(iter(test_dl_geo))\n",
    "print(batch_geo)\n",
    "print('-'*80)\n",
    "print(test_dataset_geo[0])\n",
    "print(test_dataset_geo[1])\n",
    "print(test_dataset_geo[2])\n",
    "print(test_dataset_geo[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch의 module을 활용한 graph dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData:\n",
    "    def __init__(self, x, edge_index=[[], []], edge_attr=None, y=None, id=None):\n",
    "        self._x = x.float() if isinstance(x, torch.Tensor) else torch.tensor(x).float()\n",
    "        self._edge_index = edge_index.long() if isinstance(edge_index, torch.Tensor) else torch.tensor(edge_index).long()\n",
    "        \n",
    "        self._edge_attr = edge_attr\n",
    "        if edge_attr is not None:\n",
    "            self._edge_attr = edge_attr.float() if isinstance(edge_attr, torch.Tensor) else torch.tensor(edge_attr).float()\n",
    "            \n",
    "        self._y = y\n",
    "        if y is not None:\n",
    "            # single label task를 가정했음. 일반적으로, label이 여러개라면 (num_data, num_label) 이 되어야 함\n",
    "            self._y = y.view(-1,1) if isinstance(y, torch.Tensor) else torch.tensor(y).view(-1,1) \n",
    "        \n",
    "        self._id = id\n",
    "        n = self._x.shape[0]\n",
    "        self._batch = torch.tensor([0] * n).long()\n",
    "        self._ptr = torch.tensor([0, n]).long()\n",
    "    \n",
    "    @property\n",
    "    def x(self):\n",
    "        return self._x\n",
    "\n",
    "    @x.setter\n",
    "    def x(self, value):\n",
    "        if self._x.shape != value.shape:\n",
    "            raise ValueError('Invalid setting data', self._x.shape, value.shape)\n",
    "        self._x = value\n",
    "\n",
    "    @property\n",
    "    def edge_index(self):\n",
    "        return self._edge_index\n",
    "\n",
    "    @property\n",
    "    def edge_attr(self):\n",
    "        return self._edge_attr\n",
    "\n",
    "    @edge_attr.setter\n",
    "    def edge_attr(self, value):\n",
    "        if self._edge_attr.shape != value.shape:\n",
    "            raise ValueError('Invalid setting data', self._edge_attr.shape, value.shape)\n",
    "        self._edge_attr = value\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, value):\n",
    "        if self._y.shape != value.shape:\n",
    "            raise ValueError('Invalid setting data', self._y.shape, value.shape)\n",
    "        self._y = value\n",
    "\n",
    "    @property\n",
    "    def id(self):\n",
    "        return self._id\n",
    "    \n",
    "    @property\n",
    "    def batch(self):\n",
    "        return self._batch\n",
    "    \n",
    "    @property\n",
    "    def ptr(self):\n",
    "        return self._ptr\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self):\n",
    "        return self._x.shape[0]\n",
    "\n",
    "    @property\n",
    "    def num_node_features(self):\n",
    "        return self._x.shape[1]\n",
    "\n",
    "    @property\n",
    "    def num_edges(self):\n",
    "        return self._edge_attr.shape[0]\n",
    "\n",
    "    @property\n",
    "    def num_edge_features(self):\n",
    "        return self._edge_attr.shape[1]\n",
    "    \n",
    "    def to(self, device):\n",
    "        self._x = self._x.to(device)\n",
    "        self._edge_index = self._edge_index.to(device)\n",
    "        self._edge_attr = self._edge_attr.to(device)\n",
    "        self._y = self._y.to(device)\n",
    "        self._batch = self._batch.to(device)\n",
    "        self._ptr = self._ptr.to(device)\n",
    "        \n",
    "class TorchDataset(pdat.Dataset):\n",
    "    def __init__(self, mp_dataset, target='band_gap', r=3):\n",
    "        super(TorchDataset, self).__init__()\n",
    "        self._data = []\n",
    "        for mp_data in mp_dataset:\n",
    "            data = strucutre_to_graph(mp_data['structure'], r=r)\n",
    "            self._data.append(MyData(\n",
    "                x = data['x'], \n",
    "                edge_index = data['edge_index'].T, \n",
    "                edge_attr = data['edge_attr'].reshape(-1,1),\n",
    "                y = mp_data[target],\n",
    "                id = mp_data['material_id'],\n",
    "            ))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            return [self._data[_i] for _i in i]\n",
    "        except:                \n",
    "            return self._data[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def to(self, device):\n",
    "        for d in self._data:\n",
    "            d.to(device)\n",
    "        return self\n",
    "        \n",
    "def my_collate_fn(dataset):\n",
    "    x = []\n",
    "    edge_attr = []\n",
    "    edge_index = []\n",
    "    y = []\n",
    "    batch = []\n",
    "    ptr = [0]\n",
    "    id = []\n",
    "    n = 0\n",
    "    for i, data in enumerate(dataset):\n",
    "        x.append(data.x)\n",
    "        if data.y is not None: y.append(data.y)\n",
    "        if data.edge_attr is not None: edge_attr.append(data.edge_attr)\n",
    "        \n",
    "        edge_index.append(data.edge_index + n)\n",
    "        batch.append(data.batch +i)\n",
    "        n += data.num_nodes\n",
    "        ptr.append(n)\n",
    "        id.append(data.id)\n",
    "        \n",
    "    collated_data = MyData(\n",
    "        x = torch.concat(x, dim=0),\n",
    "        edge_attr = torch.concat(edge_attr, dim=0) if len(edge_attr) != 0 else None,\n",
    "        edge_index = torch.concat(edge_index, dim=1),\n",
    "        y = torch.concat(y, dim=0) if len(y) != 0 else None,\n",
    "        id = id\n",
    "    )\n",
    "    collated_data._batch = torch.concat(batch, dim=0)\n",
    "    collated_data._ptr = torch.tensor(ptr).long()\n",
    "    return collated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_tch = TorchDataset(test_data)\n",
    "test_dl_tch = pdat.DataLoader(test_dataset_tch, batch_size=4, collate_fn=my_collate_fn)\n",
    "batch_tch = next(iter(test_dl_tch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape\n",
      "torch.Size([92, 6]) torch.Size([92, 6])\n",
      "\n",
      "batch\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
      "\n",
      "edge_index\n",
      "tensor([[90, 90, 91, 91, 91, 91, 91, 91, 91, 91],\n",
      "        [73, 83, 86, 90, 87, 80, 76, 82, 79, 83]])\n",
      "tensor([[90, 90, 91, 91, 91, 91, 91, 91, 91, 91],\n",
      "        [73, 83, 86, 90, 87, 80, 76, 82, 79, 83]])\n"
     ]
    }
   ],
   "source": [
    "print('x shape')\n",
    "print(batch_geo.x.shape, batch_tch.x.shape)\n",
    "print('\\nbatch')\n",
    "print(batch_geo.batch[-10:])\n",
    "print(batch_tch.batch[-10:])\n",
    "print('\\nedge_index')\n",
    "print(batch_geo.edge_index.T[-10:].T)\n",
    "print(batch_tch.edge_index.T[-10:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mp-755646', 'mp-1178103', 'mp-760833', 'mp-1235061']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tch.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_traj_data = json.load(open('../data/mp_traj_LiSiO.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN을 이용한 특성 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CGConv layer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.CGConv.html#torch_geometric.nn.conv.CGConv)를 이용한 [CGCNN](https://github.com/txie-93/cgcnn) 구조 재현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGCNN(pnn.Module):\n",
    "    def __init__(self, \n",
    "                 num_node_features, \n",
    "                 num_edge_features,\n",
    "                 num_output_dim=1, \n",
    "                 num_atom_features=64, num_hidden_features=128,\n",
    "                 num_convolution=3, num_hidden_layers=1\n",
    "                 ):\n",
    "        # num_node_features : orig_atom_fea_len\n",
    "        # num_edge_features : nbr_fea_len\n",
    "        # num_atom_feature : atom_fea_len\n",
    "        # num_hidden_features : h_fea_len\n",
    "        # num_convolution : n_conv\n",
    "        # num_hidden_layers : n_h\n",
    "        super(CGCNN, self).__init__()\n",
    "        \n",
    "        self.embedding = pnn.Linear(num_node_features, num_atom_features)\n",
    "        \n",
    "        conv_layers = []\n",
    "        for _ in range(num_convolution):\n",
    "            conv_layers.append(\n",
    "                # layer를 tuple로 정의하며, \n",
    "                # 첫 번째 항목에는 layer object\n",
    "                # 두 번째 항목에는 layer의 input/output\n",
    "                (\n",
    "                    gnn.CGConv(channels=num_atom_features,\n",
    "                               dim=num_edge_features,\n",
    "                               batch_norm=True),\n",
    "                    'x, edge_index, edge_attr -> x'\n",
    "                )\n",
    "            )\n",
    "        # pooling layer의 정의\n",
    "        # pooling layer에서는 data의 batch 정보를 이용해서 \n",
    "        # 각 graph에 있는 정보를 하나로 모음\n",
    "\n",
    "        # e.g.) \n",
    "        #   1st crystal: 0-5 atoms -> 1st pooled data\n",
    "        #   2nd crystal: 6-14 atoms -> 2nd pooled data\n",
    "        #   3rd crystal: 15-22 atoms -> 3rd pooled data\n",
    "        # 22 data (if 22 atoms from 3 crystals) -> pooling -> 3 data (if 3 graphs)\n",
    "        \n",
    "        # add, mean, max 세 종류가 가장 많이 쓰임\n",
    "        conv_layers.append((gnn.global_mean_pool, 'x, batch -> x'))\n",
    "        \n",
    "        # 정의한 conv_layers를 sequential을 이용해 하나로 묶어줌\n",
    "        # pytorch의 sequential과는 다르게, 첫 번째 항목에는 input attribution을, \n",
    "        # 두 번째 항복에는 tuple로 구성된 layer list를 넣어줌\n",
    "        # i.e.) pytorch의 sequential은 layer 요소를 분할해서 넣어야 했음 (*표시)\n",
    "        self.conv_layers = gnn.Sequential(\n",
    "            'x, edge_index, edge_attr, batch', conv_layers\n",
    "        )\n",
    "\n",
    "        fc_layers = [\n",
    "            pnn.Softplus(), \n",
    "            pnn.Linear(num_atom_features, num_hidden_features),\n",
    "            pnn.Softplus(),\n",
    "        ]\n",
    "        for _ in range(max(num_hidden_layers - 1, 0)):\n",
    "            fc_layers.append(pnn.Linear(num_hidden_features, num_hidden_features))\n",
    "            fc_layers.append(pnn.Softplus())\n",
    "        \n",
    "        # pytorch의 sequential에 정보 입력\n",
    "        self.fc_layers = pnn.Sequential(*fc_layers)\n",
    "        self.output = pnn.Linear(num_hidden_features, num_output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h_embed = self.embedding(data.x)\n",
    "        h_conv = self.conv_layers(x = h_embed,\n",
    "                                  edge_attr=data.edge_attr, \n",
    "                                  edge_index = data.edge_index,\n",
    "                                  batch = data.batch)\n",
    "        h_fc = self.fc_layers(h_conv)\n",
    "        out = self.output(h_fc)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band gap 예측 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필요한 custom library 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['requirements.txt', 'src', 'data', 'notebooks', 'memo.txt', '.git', '.credential.json', 'lecture.pptx', 'output', '.gitignore']\n",
      "['utils.py']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(os.listdir('..'))\n",
    "sys.path.append('../src')\n",
    "print(os.listdir('../src'))\n",
    "from utils import PyGTrainer, CrossValidation, StandardGraphScaler, save_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "train_dataset = TorchDataset(train_data, target='band_gap', r=3).to(device)\n",
    "test_dataset = TorchDataset(test_data, target='band_gap', r=3).to(device)\n",
    "\n",
    "train_label = torch.concat([d.y for d in train_dataset], dim=0).cpu().numpy()\n",
    "test_label = torch.concat([d.y for d in test_dataset], dim=0).cpu().numpy()\n",
    "\n",
    "scaler = StandardGraphScaler(['x','edge_attr','y'])\n",
    "scaled_train_dataset = scaler.fit_transform(train_dataset)\n",
    "scaled_test_dataset = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scaler 정상 작동 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale된 test 데이터의 label (y) 값만 가져오기\n",
    "scaled_test_label = torch.concat([_d.y for _d in scaled_test_dataset], dim=0).cpu()\n",
    "# scale된 test label를 복원하기\n",
    "restored_test_label = scaler.inverse_transform_vector(scaled_test_label.to('cuda'), 'y').to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6464, 0.3103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2173,\n",
       "          0.5175, 1.3041, 0.0000, 1.1310, 0.0916, 0.0000, 1.8409, 0.0841, 0.5482,\n",
       "          0.0000, 0.0000]]),\n",
       " tensor([[-0.0643, -0.3627, -0.6382, -0.6382, -0.6382, -0.6382, -0.6382, -0.6382,\n",
       "          -0.4453, -0.1787,  0.5197, -0.6382,  0.3660, -0.5569, -0.6382,  0.9964,\n",
       "          -0.5636, -0.1515, -0.6382, -0.6382]]),\n",
       " tensor([[0.6464, 0.3103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2173,\n",
       "          0.5175, 1.3041, 0.0000, 1.1310, 0.0916, 0.0000, 1.8409, 0.0841, 0.5482,\n",
       "          0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[:20].T, scaled_test_label[:20].T,  restored_test_label[:20].T, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "test_dl = pdat.DataLoader(scaled_test_dataset, batch_size=256, collate_fn=my_collate_fn)\n",
    "CV = CrossValidation(train_dataset, cv=5, return_index=True, seed=123)\n",
    "\n",
    "for i in range(5):\n",
    "    train_idx, valid_idx = CV[i]\n",
    "    train_dl = pdat.DataLoader(scaled_train_dataset, batch_size=32, sampler=SubsetRandomSampler(train_idx), collate_fn=my_collate_fn)\n",
    "    valid_dl = pdat.DataLoader(scaled_train_dataset, batch_size=256, sampler=valid_idx, collate_fn=my_collate_fn)\n",
    "    \n",
    "    model = CGCNN(\n",
    "        num_node_features = test_dataset[0].num_node_features,\n",
    "        num_edge_features = test_dataset[0].num_edge_features,\n",
    "    ).to(device)\n",
    "    \n",
    "    crit = pnn.MSELoss()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    tr = PyGTrainer(model, opt, crit)\n",
    "    \n",
    "    output_path = f'../output/matproj/bandgap/cv_{i:02d}'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    writer = SummaryWriter(output_path)\n",
    "    best_loss = 1e5\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = tr.train(train_dl)\n",
    "        valid_loss, valid_result = tr.eval(valid_dl)\n",
    "        test_loss, test_result = tr.eval(test_dl)\n",
    "        \n",
    "        valid_pred = scaler.inverse_transform_vector(valid_result.to(device), 'y').to('cpu').numpy()\n",
    "        test_pred = scaler.inverse_transform_vector(test_result.to(device), 'y').to('cpu').numpy()\n",
    "        \n",
    "        valid_r2 = r2_score(train_label[valid_idx], valid_pred)\n",
    "        valid_mae = mean_absolute_error(train_label[valid_idx], valid_pred)\n",
    "        test_r2 = r2_score(test_label, test_pred)\n",
    "        test_mae = mean_absolute_error(test_label, test_pred)\n",
    "        \n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Valid', valid_loss, epoch)\n",
    "        writer.add_scalar('Loss/Test', test_loss, epoch)   \n",
    "        writer.add_scalar('R2/Valid', valid_r2, epoch)   \n",
    "        writer.add_scalar('R2/Test', test_r2, epoch)   \n",
    "        writer.add_scalar('MAE/Valid', valid_mae, epoch)   \n",
    "        writer.add_scalar('MAE/Test', test_mae, epoch)\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            save_output(output_path, f'{epoch:04d}.valid.pkl', valid_result)\n",
    "            save_output(output_path, f'{epoch:04d}.test.pkl', test_result)\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            save_output(output_path, f'best.valid.pkl', valid_result)\n",
    "            save_output(output_path, f'best.test.pkl', test_result)\n",
    "            with open(os.path.join(output_path, 'log.txt'),'w') as f:\n",
    "                f.write('Epoch: {:4d} / Train loss: {:10.5f}\\n'.format(epoch, train_loss))\n",
    "                f.write('Valid Loss / R2 / MAE : {:10.5f} / {:10.5f} / {:10.5f}\\n'.format(valid_loss, valid_r2, valid_loss))\n",
    "                f.write('Test Loss / R2 / MAE  : {:10.5f} / {:10.5f} / {:10.5f}\\n'.format(test_loss, test_r2, test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
